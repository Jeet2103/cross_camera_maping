# ğŸ¥ Cross Camera Mapping Project

This project is an advanced cross-view player tracking system that accurately maps and re-identifies players across broadcast and tactical camera feeds using state-of-the-art computer vision techniques.

## âœ¨ Key Features
- **Multi-Camera Tracking**: Seamless player identification across different views
- **Advanced Algorithms**: Combines YOLOv11, StrongSORT, and OSNet
- **Real-Time Processing**: Efficient pipeline for sports analytics
- **Precise Mapping**: Homography transformation for accurate position mapping
- **Fast Matching**: FAISS-based similarity search for player re-identification

## ğŸ› ï¸ Technical Stack
- **Detection**: YOLOv11
- **Tracking**: StrongSORT
- **Features Extraction**: OSNet
- **Geometry**: Homography Transformation
- **Matching players**: FAISS

---
## ğŸ“ Project Structure
```
cross_camera_mapping/
â”œâ”€â”€ data/ # Input video files
â”‚ â”œâ”€â”€ broadcast.mp4 # Broadcast camera feed
â”‚ â””â”€â”€ tacticam.mp4 # Tactical camera feed
â”‚
â”œâ”€â”€ model/ # Model weights
â”‚ â””â”€â”€ best.pt # YOLOv11 model file
â”‚
â”œâ”€â”€ detections/ # Player detection outputs(.csv file)
â”œâ”€â”€ tracking/ # Player tracking data(.csv file)
â”œâ”€â”€ mapping/ # Camera mapping data(.npy files and json file)
â”œâ”€â”€ output/ # Final output files(.mp4 file)
â”œâ”€â”€ logs/ # System logs
â”‚
â”œâ”€â”€ logger_config/ # Logging configuration
â”‚ â””â”€â”€ logger.py # Logger implementation
â”‚
â”œâ”€â”€ compute_homography.py # Homography calculations
â”œâ”€â”€ pipeline.py # Main processing pipeline
â”‚
â”œâ”€â”€ detect_players.py # Player detection script
â”œâ”€â”€ track_players.py # Player tracking script
â”œâ”€â”€ extract_features.py # Feature extraction
â”œâ”€â”€ match_players.py # Player matching across views
â”œâ”€â”€ visualize_results.py # Visualization utilities
â”‚
â””â”€â”€ requirements.txt # Project dependencies
```
---

## ğŸš€ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/Jeet2103/cross_camera_maping.git
cd cross_camera_maping

```


### 2. Create and Activate a Virtual Environment

You can use either `venv` or `conda` to manage your environment.

**Using `venv`:**

- **For Windows:**
  - Create: `python -m venv venv`
  - Activate: `venv\Scripts\activate`

- **For Linux/MacOS:**
  - Create: `python3 -m venv venv`
  - Activate: `source venv/bin/activate`

**Using `conda`:**

- Create: `conda create -n ccm_env python=3.9`
- Activate: `conda activate ccm_env`

### 3. Install Dependencies

Install all required dependencies using the following command:


`pip install -r requirements.txt`

## Dependencies

The project requires the following Python packages:

- ultralytics  
- opencv-python  
- torch  
- torchvision  
- numpy  
- pandas  
- matplotlib  
- deep-sort-realtime  
- scikit-learn  
- torchreid  
- tensorboard  
- cython  
- charset-normalizer  
- chardet  
- faiss-cpu  

Python version: **3.9 or above**


### 4: Download YOLOv11 Model

Download the YOLOv11 model from the following link:

[Download YOLOv11](https://drive.google.com/file/d/1-5fOSHOSB9UXyP_enOoZNAMScrePVcMD/view)

After downloading, place the model file (`best.pt`) inside the `model/` directory:



## ğŸ‘ŒRunning the Project

After installation, run the main pipeline using:

`python pipeline.py`

This will perform detection, tracking, feature extraction, and cross-camera matching, and generate output with visual identity mapping.

## Contact

Maintained by **Jeet Nandigrami**  
- GitHub: [Jeet2103](https://github.com/Jeet2103)  
- LinkedIn: [Jeet Nandigrami](https://www.linkedin.com/in/jeet-nandigrami/)
- Resume : [RESUME](https://drive.google.com/file/d/1Zvm0yAK--t_K-lNBpLnDFA2Lz41ZBqvX/view?usp=sharing)