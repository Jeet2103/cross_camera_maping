# Brief Report: Cross-View Player Mapping & Re-identification System

The objective of this project is to build an advanced cross-view player tracking and re-identification system that effectively maps and tracks players across broadcast and tactical (top-down) camera views. In sports analytics, especially in football or basketball, player identities often become ambiguous when switching between different camera feeds. This system addresses that challenge by ensuring consistent player identification across disjoint views, enabling deeper insights into player movements, formations, and tactical decisions.

## Approach and Methodology

### 1. Player Detection with YOLOv11

- **Objective:**
For precise and high-speed detection of players, the system utilizes the YOLOv11 (You Only Look Once version 11) object detection framework—renowned for its cutting-edge performance on both GPU and edge devices.

- **Model Used:** A fine-tuned YOLOv11 model named best.pt, trained on a sports-specific dataset to recognize multiple classes relevant to the game:
    - Player, Goalkeeper, Referee, and Ball.
- **Methodology:**

    - **Multi-Class Detection:** Accurately detects and differentiates between players, goalkeepers, referees, and the ball in real-time.

    - **Color-Coded Bounding Boxes:** Each class is rendered with a distinct bounding box color for intuitive visual feedback.

    - **Advanced Detection Head:** Enhanced localization and classification, especially in high-density scenes with overlapping individuals.

    - **Temporal Consistency:** The detector has been optimized to maintain consistent detection across frames, reducing ID switches and missed detections in fast-paced scenes.

- **Output:**
    - Detected bounding boxes with class labels (`player`, `goalkeeper`, `referee`, `ball`) and confidence scores.

    - For both the broadcast view and the tactical view videos, the detection module automatically generates two CSV files with the following format: `frame_id`, `x1`, `y1`, `x2`, `y2`, `confidence_score`, `class`

    - These outputs are forwarded to the tracking pipeline for identity assignment and continuity across frames.

- **Implementation File:**
    - **Filename:** `detect_players.py`

### 2. Player Tracking with StrongSORT

- **Objective:**
To ensure consistent identification of players across time, the system implements StrongSORT — a powerful real-time multi-object tracking (MOT) framework. It is a robust extension of DeepSORT, designed specifically to handle the challenges of dense scenes, occlusions, and rapid movements commonly observed in sports footage.

- **Methodology:**
    - **Input:** CSVs from `detect_players.py` containing detections (`frame ID`, `bounding boxes`, `confidence`, `class`).

    - **Motion Modeling:** Uses a Kalman Filter to estimate and predict player positions frame by frame.

    - **Appearance Embedding:** Integrates ReID features to preserve identity even during occlusions or overlaps.

    - **Track ID Assignment:** Assigns a unique track_id to each player per view that remains consistent as long as the player is visible.

- **Output:**
    - Generates two tracking CSVs, one for each video containing `frame_id`, `track_id`, `x1`, `y1`, `x2`, `y2`, `class`
    - Used for further cross-view matching and features extraction.
    - Each tracking step is logged using the custom `logger.py` for transparency and debugging.
- **Implementation File:**
    - **Filename:** `track_players.py`

### 3. Appearance & Spatial Feature Extraction with OSNet

- **Objective:**
To accurately match players across different camera views, the system extracts appearance and spatial features using a powerful feature extraction pipeline based on the OSNet model and homography transformation.
- **Methodology:**
    - **Appearance Feature Extraction:** The system uses the `OSNet_x1_0` model from Torchreid's FeatureExtractor to generate high-dimensional appearance embeddings for each player by cropping their regions from sampled video frames.

    - **Tracking Data Processing:** Player tracking data, including bounding box coordinates and IDs, is read from CSV files generated by `track_players.py`.

    - **Spatial Alignment via Homography:** Each bounding box’s center point is transformed using a precomputed homography matrix to align spatial features across multiple camera views.

    - **Feature Aggregation & Logging:** Appearance and spatial features are averaged across frames to form a compact player representation, with all operations and exceptions logged using a custom logger (`extract_features.log``).

- **Output:**
    - This module generates two `.npy` files (`broadcast_features.npy` and `tacticam_features.npy`) stored in the `mapping/features/ directory`. Each entry maps a unique `track_id` to a feature vector that includes both appearance and spatial information. These files are critical for downstream cross-view player matching.
- **Implementation File**
    - **File Name**: `extract_features.py`

### 4. Cross-View Player ID Matching

- **Objective:**
This module aims to establish a one-to-one mapping between players detected and tracked in two distinct camera views—broadcast and tacticam. The goal is to maintain consistent player identity across views for enhanced analytics and tactical insights.
- **Methodology:**
The system loads player-level appearance and spatial features from two .npy files generated by `extract_features.py`. Each player's feature vector is split into two parts: a 2048-dimensional appearance embedding and a 2D spatial coordinate (`transformed via homography`).
To match players:

    - Features are normalized and concatenated.

    - A cost matrix is computed using a weighted combination of appearance similarity (`cosine distance`) and spatial proximity (`Euclidean distance`).

    - The Hungarian algorithm (`linear_sum_assignment`) is used to optimally solve the assignment problem.

Thresholding is applied to eliminate weak matches. Each accepted mapping is logged with a confidence score, and unmatched players are skipped with a warning for transparency.

- **Output:**
    - A JSON file id_mapping.json is saved in the `mapping/ directory`, mapping each `track_id` from the tacticam video to its corresponding ID in the broadcast view. This mapping ensures identity consistency for visualization and further tactical interpretation.

    - All processing steps, score thresholds, and exceptions are traced via `match_players.log`.

- **Implementation File:**
    - **Filename:** `match_players.py`